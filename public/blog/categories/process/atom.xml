<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Process | The Technician]]></title>
  <link href="http://yoursite.com/blog/categories/process/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2013-03-09T00:07:54-05:00</updated>
  <id>http://yoursite.com/</id>
  <author>
    <name><![CDATA[Chris Henry]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Argument for Generalists in Web Development]]></title>
    <link href="http://yoursite.com/2012/07/09/the-argument-for-generalists-in-web-development/"/>
    <updated>2012-07-09T00:00:00-04:00</updated>
    <id>http://yoursite.com/2012/07/09/the-argument-for-generalists-in-web-development</id>
    <content type="html"><![CDATA[<p>"An expert is one who knows more and more about less and less until he knows
absolutely everything about nothing"
-<a href="https://twitter.com/mastersje/status/192257585745891330">@mastersje</a></p>

<p>My grandfather was a carpenter. He had an immense workbench, with a pegboard
that had hundreds of hammers, screwdrivers, wrenches, saws, drills, planes,
awls. They were powered, hand powered, circular, rotary and reciprocating.
Each of them had their own beauty, and their own use. The man could build a
picture frame, a desk, a dock, or an entire house. He may not have wielded any
of them expertly, but he knew which one to use when the situation called, and
he certainly knew how to use them in concert.</p>

<p>Two generations later, I have become a web developer, and can't help but
notice the similarities between the two. He worked in wood, but I work in bits
and bytes. Web sites, especially big ones, are not the product of a single
technology, but the result of many technologies seamlessly interacting.
Building a house is no different. Framing, roofing, laying foundation are all
separate skills that require vastly different tools. Part of the challenge of
being a web developer is being able to manage lots of technologies at once.</p>

<p>Great web developers are carpenters. Just like carpentry, there is always the
right tool for the job. Infrastructure that doesn't play well with software is
bound for failure. Software that doesn't use or fit the hardware / kernel / OS
well won't run well. As experts in web development, we can know less about
each technology, but should know more about how they work together. Tailoring
software or combinations of software packages is the magic bullet that solves
problems quickly and scalably.</p>

<p>In the context of early stage startups, generalists are a better bet for
getting a production up and running. Even as a team grows, having generalists
around means you can task a single developer with developing and entire
feature. With a bit of support from specialists, they can pull off shipping a
feature faster than a team of a couple of specialists. When widespreadÂ  issues
occur, I prefer to have a generalist in my corner, because they typically
understand the the connective tissue of a website very well, and are willing
to put in the time debugging from a variety of perspectives.</p>

<p>None of this is to say that specialists don't have their place in web
development. The web is an innovative medium that it has spawned dozens of
technologies (node.js) that require a deep pool of expertise to work in. There
are vast arrays of techniques and frameworks that cater to working in a single
technology. Generalists typically won't have the depth necessary to pull off a
awe-inspiring, truly nasty implementation. However, they'll have the right
instincts to pair it, deploy, and make it do something meaningful that a
specialist might not be able to do by themselves.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Workflow with Synergy]]></title>
    <link href="http://yoursite.com/2012/05/26/workflow-with-synergy/"/>
    <updated>2012-05-26T00:00:00-04:00</updated>
    <id>http://yoursite.com/2012/05/26/workflow-with-synergy</id>
    <content type="html"><![CDATA[<p>As a web developer working in lots of different areas, I have to use <a href="http://blog.behance.net/dev/developers-toolkit-chris-%0Ahenry">lots of
different programs</a> to perform various tasks. Terminal for SSH, Eclipse for php, etc.
Chrome for all things web browsing, including Gmail. Eventually, the number of
tabs I needed to keep open during the day caused my gmail tabs to get lost
pretty easily, even after using the pin feature. Then I stumbled upon
<a href="http://mailplaneapp.com/new_index">Mailplane</a>. Mailplane is a stellar program
that turns gmail into a desktop app.</p>

<p>After adding yet another app to my stable, it seemed necessary to divide my
screen real estate into spaces. Part of the problem of having so many
different programs is the problem of context. Once situating the necessary
programs in a way that makes sense for the particular task, changing context
can completely knock me out of my flow. For a period of time, it didn't even
make sense to use Mailplane, as it was easier to actually switch over to my
phone, and read / respond to email there.</p>

<p>Then it hit, why not just bring in my laptop, and deal with email there. So I
started bringing my laptop. This was awesome, as it allowed me to deal with
email on relatively normal sized screen and keyboard. The next issue was
dealing with links in emails. After asking the twitterverse and stackexchange,
I finally settled on <a href="http://synergy-foss.org/">Synergy</a>. Synergy allows you
to seamless share your keyboard and mouse between any number of machines. So I
started running Mailplane in fullscreen mode on a laptop situated next to my
desktop. To get to my email, I just mouse all the way to the left, and voila,
I can use a full keyboard / mouse with a laptop. If I need to open links on
the big screens, I just copy and use Chrome's paste &amp; go feature.</p>

<p>This works tremendously well, as I can leave any development task as is on my
desktop without having to worry about shuffling things around. It also helps
tremendously when applying pesky software updates, as you always have one
machine that will be up and running.</p>

<p><a href="/images/user/workflow_synergy.jpg"><img src="/images/user/workflow_synergy.jpg" alt="Rig at the Behnace Office" /></a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Distributed Updates]]></title>
    <link href="http://yoursite.com/2011/06/25/distributed-updates/"/>
    <updated>2011-06-25T00:00:00-04:00</updated>
    <id>http://yoursite.com/2011/06/25/distributed-updates</id>
    <content type="html"><![CDATA[<p>Part of managing any large site involves writing scripts that will go through
oyur data, make changes, merge things, remove things, do type transformations,
etc. Most of the time, in PHP, iterating through rows or objects will do just
fine. However, when there are lots of rows or objects, you could be faced with
a script that takes hours or days to run. Depending on how often active the
is, you may need to restrict access to ensure that the data before and after
the transformation remains consistent. In other words, if someone tries to
make a change to the data before the transformation, and the new feature only
looks at data after the transformation, that user has just lost their changes.
That is Very Bad.</p>

<p>As sites get larger and problems like this loom, taking the site offline
becomes less and less of an option. This is what the business team calls a
luxury problem, and what the ops team refers to simply as a problem. One
option is to write a more efficient script. You can get pretty far by simply
ensuring you're reading from the fastest data source available, make good use
of cache, etc. ensure that the tables being read for the transformation are
properly indexed. All of these are great places to start. Additionally, making
sure that data is grabbed in chunks can give the database time to breathe.
There's nothing worse than getting stuck in MySQL's "sending data" phase
simply because it needs to read several thousand rows from disk. MySQL
configuration can also be your friend here. If using InnoDB, increasing the
insert buffer is a great way to speed up writes.*</p>

<p>However, as much as you can do to speed up a single transaction, the fact
remains that you have to execute each transformation serially, one after
another. Your bottleneck is the transformation itself. It will take (# of
transformations * # of objects to transform) to complete the job. No matter
how well tuned the database is, it will only be performing one operation at a
time, which means that the other (max connections - 1) connections are doing
precisely crap. So the next logical step is to change your update script to
distribute the update operations so a few can be run in parrallel.</p>

<p>Rewriting the update script does require thinking about your update
differently, and will not work in every case. For example, if one is simply
moving a large amount of data from one table to another, and there is no
transformation, or the transformation can be accomplished via a builtin MySQL
function, use that. However, just be prepared to deal with locking issues, and
the source data potentially not being available while the transformation is
taking place. However, if your transformation is complicated, and requires
per-case logic, this is definitely a good route to take. The biggest
difference is how the code for the update is organized. The update script
needs to be separated out into code that will apply the transformation for
exactly one entity, and code that will manage which entities get transformed
and when. Ideally, the code for the transformation is idempotent, so failures
can be handled by simply resubmitting the entity / object to be transformed
again.</p>

<p>Accomplishing parallel processing in PHP can be kind of tricky. Php's
pcntl_exec function has always felt a bit finicky to me. Of course exec on its
own it blocking, so that's out. Additionally, neither of these solutions offer
any sort of baked-in communication between the process that submitted the job,
and the process carrying out the job. That leaves us with a queuing system.
Popular systems include: RabbitMQ and Gearman. Personally, I've made great use
of <a href="http://chr.ishenry.com/2009/07/25/gearman/">Gearman</a>. It's easy to
install, as is the PHP module.</p>

<p>To sum up, performing large data updates via a distributed system is the way
to go if you have complex requirements per transformation, and the option to
perform these processes in parallel.</p>

<p>*If using MySQL's MyISAM engine, this isn't necessarily true, as writes will block, and the database could become the bottleneck. However, since MySQL is continuing to push InnnDB, this is getting increasingly unlikely. So if your tables are all InnoDB, you're probably in good shape.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Emergencies will audit the shit out of you]]></title>
    <link href="http://yoursite.com/2010/10/21/emergencies-will-audit-the-shit-out-of-you/"/>
    <updated>2010-10-21T00:00:00-04:00</updated>
    <id>http://yoursite.com/2010/10/21/emergencies-will-audit-the-shit-out-of-you</id>
    <content type="html"><![CDATA[<p>Things never go wrong at convenient times: Like when you're auditing the
latest, coolest version of your app, and looking for bugs. Things have a funny
way of working out fine <strong>then</strong>. However, soon as you look the other way, a
multitude of problems come out of the woodwork. It usually goes something like
this:</p>

<p>One server goes down, and the system that was supposed to fail silently starts
screaming. The application it was supporting goes down, because the proper
timeouts and error handling was never written. You can't fail over, because
failing over will take down 2 other applications. When that first server comes
back up, nothing works, because the proper startup scripts were never put in
place. Once the right services start, if you can remember what the hell they
were, you find the original application is configured wrong. Not only is it
configured wrong, it's <strong><em>always</em></strong> been configured wrong, and no one noticed.
No one noticed because it only explodes in the exact set of horrible
circumstances you have right now. Which is, by the way, being down.</p>

<p>It's an all-too-familiar story, and one that even most the anal of admins has
dealt with. The fact of the matter is that it is going to happen, and there's
not a whole lot you can do to prepare, other than randomly pulling plugs out
of servers. But with any mistake that causes downtime, it should <a href="http://l.chr.ishenry.com/fail">only happen
once</a>. Proper postmortem examination needs to
be taken here to figure out what went wrong where. Once all the variables are
understood, the next step is to duplicate the same set of circumstances in
your <a href="http://l.chr.ishenry.com/sbx">sandbox</a>, and apply the necessary error
handling.</p>

<p>Downtime and emergencies are a part of running any site. What's really
important is to treat emergencies as an opportunity to learn about what
happens when systems fail, for real.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Accountability is a Feedback Loop]]></title>
    <link href="http://yoursite.com/2010/06/23/accountability-is-a-feedback-loop/"/>
    <updated>2010-06-23T00:00:00-04:00</updated>
    <id>http://yoursite.com/2010/06/23/accountability-is-a-feedback-loop</id>
    <content type="html"><![CDATA[<p><a href="http://wordnetweb.princeton.edu/perl/webwn?s=accountability">Accountability</a>
is a word that's getting tossed around a lot lately. You hear people saying
things like:</p>

<blockquote><ul>
<li><p>That developer should be held accountable for the validation problems.</p></li>
<li><p>The tester should be accountable for not finding that bug.</p></li>
<li><p>BP needs to be accountable for destroying an ecosystem.</p></li>
</ul>
</blockquote>

<p>The term seems to be thrown around most often when parts of a system fail. BP
is part of a larger industry which that's regulated. The government agency
responsible for monitoring safety measures is responsible for ensuring they
follow safety regulations. So when BP made their <a href="http://twitter.com/bpglobalpr/status/14583761878">whoopsie
daisy</a>, the fingers were
pointed squarely at them. However, where were the regulators? There were tons
of opportunities for the government to push feedback to BP regarding the
safety of their operation. But it seemed like no one was talking.</p>

<p>The development process is strikingly similar. Any development team worth
their bits has a process that puts any issue in front of at least two parties
at all times. Joel Spolsky's infamous <a href="http://www.joelonsoftware.com/articles/fog0000000029.html">Bug
1203</a>, a quick
story about the interactions between a dev and a tester, is the picture of
accountability, and shows that without active management and constant feedback
being exchanged, <strong>things don't get done</strong>.</p>

<p>A quick synopsis and commentary: Jill the tester finds a bug, and provides
feedback to the dev team via the ticket system. In doing so, Jill has started
the feedback loop, and made it the responsibility of the dev team to
investigate the issue. The dev team, as they are prone to doing, deny
responsibility for the issue, and mark the issue as 'NOT A BUG' Having done
so, they've put the onus on Jill to prove it's <em>really</em> a bug, which she does
(probably in about 2 seconds). It's again the responsibility of the dev team
to fix the bug, which they do. Jill confirms the fix, and thereby closes the
loop.</p>

<p>What's important to realize is that in this type of process, it is the
responsibility of anyone and everyone involved to be accountable for their
role, and be focused on pushing feedback to the next person. Once there's a
break in the loop, the issue is likely to be dropped, and never fixed. The
last person holding the ball is the screwup. I'm sure someone somewhere is
really upset they didn't ask BP about that little safety measure.</p>
]]></content>
  </entry>
  
</feed>
