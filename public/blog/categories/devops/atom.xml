<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: devops | The Technician]]></title>
  <link href="http://chr.ishenry.com/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://chr.ishenry.com/"/>
  <updated>2015-04-12T18:07:55-04:00</updated>
  <id>http://chr.ishenry.com/</id>
  <author>
    <name><![CDATA[Chris Henry]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What it feels like to be DDoS'ed]]></title>
    <link href="http://chr.ishenry.com/2013/07/29/what-it-feels-like-to-be-ddosed/"/>
    <updated>2013-07-29T23:02:00-04:00</updated>
    <id>http://chr.ishenry.com/2013/07/29/what-it-feels-like-to-be-ddosed</id>
    <content type="html"><![CDATA[<p>The internet is hostile. Not because of trolls or flame wars or your opinion on gay marriage, but because people want to destroy you. For absolutely no fucking reason. DDoS attacks are the scariest thing in the world to someone running a website.</p>

<p>The alerts will trickle in at first. It'll just be a web sever or two that's squawking. Then more. Then external monitoring will go off. Pingdom will mark you as down, a painful insult to your hard work, and numerous nines. Then all of the web servers will alert as down. And those alerts will keep coming. For a large infrastructure, potentially hundreds. You'll have to quit email, or turn off notifications, or the cacophony of dings and vibrations will rattle around your brain and wrestle away whatever modicum of clarity you may have. SSH hangs, pings fail, your jump server gets squirrelly, and panic mounts. Tell your boss to get on chat. Don't email, text, or call, because those channels will be fucked, occupied by automated alerts, hosting providers, vendors, and other team members.</p>

<!-- more -->


<p>Vendors might be confused because they can't get to key pieces of infrastructure. That infrastructure and networking gear might be shared with others, which will freak everyone out more. If the attack is large enough, they may be experiencing the same feelings. You feel shitty, knowing this affected others, but you feel it later, because you can't possibly feel more feelings. Hopefully your vendors have dealt with this before. Hopefully they know what they're doing. Hopefully they'll have an update in a few minutes. Hopefully that update won't be that they null-routed your IP.</p>

<p>When the attack is several times larger than your subscribed bandwidth, service is denied. To your customers, to your team, and probably to upstream infrastructure. ISPs can't, and sometimes wont, help. In fact, they're likely to shun you. The dreaded null route, where there's no hope of coming back up anytime soon. That's the moment when there's nothing you can do because the infrastructure leading to your environment has been overwhelmed.</p>

<p>A DDoS never happens at a convenient time. They happen late at night, during a team outing, or when you just took a sleeping pill, or have a major launch to contend with. The randomness is just another thing that makes you feel helpless, and ineffective. Impotent.</p>

<p>Once you've picked up the pieces, and mitigated, or waited it out, that's when exhaustion comes. Or rage, then exhaustion. When and if you finally get to sleep the night after the attack, it'll be fleeting. You'll wake up often, check your phone, looking for alerts or a sign that it happened again. You'll wake up early the next day, nowhere near rested, go back to the office and wait.</p>

<p>Incidents beg the question "who would do such a thing?". Particularly when during your tenure, you've never done anything to hurt anyone, and  your service was designed to help people. Hell, even your competitors even respect you. The whole thing was birthed to help people, the little people, the people who always get taken advantage of. You love this site on some level, or you wouldn't be part of the response. If you don't love it, you at least feel a duty to protect it. If you don't fall into either category, and are blissfully unaware, or asleep, you're a either a prick or incompetent.</p>

<p>Once it's over, you constantly fear they'll come back. Thoughts and theories swirl about, unchecked. People will ask about the perpetrators, and you can only shrug, wearily. In the vacuum of facts, folks will supply their own theories. The conjecture about the attackers will be endless, the convo du jour.</p>

<ul>
<li>They did it for the lulz.</li>
<li>They were definitely Chinese.</li>
<li>They did because they had a botnet and nothing better to do.</li>
<li>They did it because they hate our guts.</li>
<li>It's an Eastern European douchebag.</li>
<li>There was a guy who called into support and was pissed, I bet it was him.</li>
<li>They did it because they want to hurt someone who's using the service.</li>
<li>They targeted you because of who you're working with.</li>
<li>It's some fat slob asshole who lives in his mother's basement and he didn't get any meatloaf.</li>
<li>It was Prism.</li>
</ul>


<p>Conjecture is useless. The attacker doesn't have a face. And even if it does, it's extremely unlikely you'll ever see it. The sad fact is that there will be no Liam Neeson Taken-style vengeance. You won't suddenly appear on another continent, infiltrate their lair, and punch their teeth down their throat. No matter how bad you may want to.</p>

<p>When you get into the office again, you'll likely be hailed as a hero. After all, you "fought the hackers." Deep down, even after you got everything back in place, you still feel a little bit like a failure, because it happened at all. You take the congratulations sheepishly, through bleary eyes, deathly afraid of the next attack.</p>

<p>Pragmatically, most of your energy should be focused on things like re-ip'ing your web site. Engaging with hosting providers to get mitigation services in place, talking directly to mitigation experts to see what help they can be, analyzing the attack to see if there are ports that can be closed to an attacker completely, fixing your application to handle the closing of ports that were attacked on, standing up services to get around ports being closed, altering your application to gather inputs in a more intelligent way after the hacks that were put in place assuming there would never be any serious infrastructure changes made without seriously considering them first.</p>

<p>You have a lot of work to do.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Making Decisions with Graphite]]></title>
    <link href="http://chr.ishenry.com/2013/05/05/making-decisions-with-graphite/"/>
    <updated>2013-05-05T21:01:00-04:00</updated>
    <id>http://chr.ishenry.com/2013/05/05/making-decisions-with-graphite</id>
    <content type="html"><![CDATA[<p>The DevOps mentality of "measure everything" can be really helpful in key moments when you need to make decisions. In particular, deploying two things side by side for the purposes of measurement can yield super helpful decision making information. For example, the Behance team was wanted to see how <a href="http://php.net/manual/en/book.apc.php">APC</a> stacked up against <a href="http://pecl.php.net/package/ZendOpcache">Zend Opcode Cache</a>.</p>

<!-- more -->


<p>Behance has been running APC for several years, and we've been pretty happy with it. There's the typical pain, usually in unexplainable segfaults, that comes with upgrades. However, with the most recent upgrade to PHP 5.4, the segfaults got a bit out of hand. After some investigation, it turned out that APC was on it's way out, and we should probably consider other opcode caches. However, as a rightly skeptical team, we wanted to thoroughly vet any alternative thoroughly. APC has been good to us, from a performance standpoint, and we needed to make sure that anything we changed to was as good or better.</p>

<p>For a baseline, we were already measuring performance using <a href="/2013/04/01/first-byte/">mod_log_firstbyte</a> and kicking its output to <a href="https://github.com/etsy/statsd/">statsd</a> with a <a href="http://graphite.wikidot.com/">Graphite</a> frontend. Once we confirmed that Zend actually worked with our app (not in production), we reconfigured one of our production web heads to use it. Luckily, our segfaults stopped, which was a fantastic sign. However, to satisfy our performance requirement, we needed some hard numbers.</p>

<p>Graphite has a really great <a href="http://graphite.readthedocs.org/en/0.9.10/render_api.html">API</a> that allows you to slice and dice your data in really helpful ways. Since we were interested in comparing two data series (the newly configured server, and any older server), we were able to use the <a href="http://graphite.readthedocs.org/en/0.9.10/functions.html#graphite.render.functions.diffSeries">diffSeries function</a> to graph the comparison between the two datasets, like so, and produced a graph like below.</p>

<blockquote><p>diffSeries(stats.timers.stat_thats_likely_to_be_higher, stats.timers.stat_thats_likely_to_be_lower)</p></blockquote>

<p><img src="/images/user/diffseries.png" alt="diffSeries graph" /></p>

<p>Since there's some math involved, this isn't the most straightforward graph to read. There are 3 patterns that emerge from using this function;</p>

<ul>
<li>If both series are equal, then it will produce a graph that hovers around 0.</li>
<li>If the second series is consistently lower, then the graph will be consistently > 0.</li>
<li>If the first series is consistently lower, then the graph will be consistently &lt; 0.</li>
</ul>


<p>In the case of our example, we saw a graph that was consistently above 0. This meant that Zend Opcode cache was consistently faster, to the tune of 5-10ms. Knowing that we had solved the segfaults problem, and knowing that Zend was statistically faster, the choice was super simple.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First Byte]]></title>
    <link href="http://chr.ishenry.com/2013/04/01/first-byte/"/>
    <updated>2013-04-01T23:29:00-04:00</updated>
    <id>http://chr.ishenry.com/2013/04/01/first-byte</id>
    <content type="html"><![CDATA[<p>As we all may have some idea of at this point, performance on the web is one of the keys to success. However, finding actionable performance metrics can be a challenge. In the course of a web request, there's a lot of stuff that happens. I'll briefly explain it here in a couple run-on sentences.</p>

<p>When you click on a link, your browser or client looks up the location of the server via DNS, and then sends off an HTTP request, then your poorly secured router passes it on to the demons that are your local ISP, who then fiendishly pass that same request up to a backbone, which then traverses continents, oceans or even hemispheres, finally arriving at the data center or poorly ventilated closet where the web servers for that particular site live. That web server reads in that request for your stuff (probably porn, you sicko), and begins whatever its process may be to assemble the initial HTML payload, which hopefully involves validating that the way you asked for said stuff is correct, and if it is, then connecting to a database to actually get that lovely stuff, receiving a response, and puts together an HTML page with that data on it, plus references (more on those later) to CSS and JS to format the data in a way that makes sense, and even make it look a little purty. After that exhausting operation, the web server will take the opposite route through the backbone to the succubus ISP, through your router to your computer to your browser. Once that happens, you technically only have the payload HTML, which by itself isn't a whole lot of fun, so then the browser will read aforementioned references to CSS and JS, and then make web requests for each of those files, which, btw, will follow the same process as the initial HTML payload went through, until you have all of the CSS and JS. Then you can finally improve your mind by thoughtfully reflecting on the highly intellectual prose you requested not too long ago.</p>

<!-- more -->


<p>The point of all those horribly structured sentences in the context of web performance is that a web request will often spend more time being passed around various routers than actually being processed on a web server. Therefore, the act of measuring an entire web request is a fool's errand, since you're only measuring lots of things that you as a web developer don't have any control over. In reference to my poorly written story, the only bit that you can actually change is the time when the web request is in the poorly ventilated closet, being parsed, processed, retrieved, and put together by the web server.</p>

<p>Therefore, one of the most important measurements to be recorded is the time it actually takes from when a request is received to when the server has started sending the complete result back to the client. Working on a standard LAMP (P being PHP) stack, there is no way that I'm aware of to do this out of the box. One way is to inject code into your app that will measure this, or to use a framework where this sort of functionality is built in. However, IMHO, that's not the best approach, as it's just more code that needs to be written, maintained, and could possibly explode in some strange way, affecting your users.</p>

<p>The approach that I've taken to measuring response times on the server is to use a somewhat obscure Apache module called <a href="https://code.google.com/p/mod-log-firstbyte/">mod_first_byte</a>. It's surprisingly easy to install and run, and having run it for several weeks, I haven't seen any performance issues or other oddities. Here's a quick example of how to install it.</p>

<p>``` bash</p>

<h1>make a suitable folder to hold the source</h1>

<p>install_dir=mod_firstbyte
mkdir $install_dir</p>

<h1>svn checkout the source into the install_dir</h1>

<p>svn checkout http://mod-log-firstbyte.googlecode.com/svn/trunk/ $install_dir</p>

<h1>depending on your linux flavor, you'll need a different program to compile</h1>

<p>if [ -f /etc/issue ]
  then
  distro='ubuntu'
  apache_apxs='apxs2'
  apache_conf='/etc/apache2/apache2.conf'
fi</p>

<p>if [ -f /etc/redhat-release ]
  then
  distro='redhat'
  apache_apxs='apxs'
  apache_conf='/etc/httpd/httpd.conf'
fi</p>

<h1>Use the weird apache command to compile and install the apache mod</h1>

<p>$apache_apxs -c     $install_dir/mod_log_firstbyte.c
$apache_apxs -i -a  $install_dir/mod_log_firstbyte.la</p>

<p>```</p>

<p>Now that you've complied the module into an so file, you'll need to add it to the apache conf. While you're in there, you'll also want to add the %F directive to your relevant LogFormat lines. Again, adjust for Linux flavor, and LogFormat preferences.</p>

<p>``` apache</p>

<p>LoadModule log_firstbyte_module /path/to/apache/modules/mod_log_firstbyte.so</p>

<p>LogFormat "%h %l %u %t \"%r\" %>s %b %F" common</p>

<p>```</p>

<p>For ease of parsing, I recommend putting the %F flag at the end. I've been using a simple php script that runs every few seconds to grep for the last couple lines that have URLs I'm interested in measuring, pulling the %F off the end of the line, and then sending the value off to <a href="https://github.com/etsy/statsd/">statsd</a>. Keep in mind that the value of %F is in microseconds, so dividing the value by 1000 to give a more reasonable number is helpful.</p>

<p>My script looks a bit like this. What I'm attempting to do is exclude anything that seems like it's a flat file, and only include URLs that are generated by going through my application. YMMV, depending on what your application is and what you want to measure exactly.</p>

<p>``` php</p>

<p>$log_lines  = array();
$cmd        = "tail -n 50 /var/log/httpd/access_log | egrep -v \"css|js|gif|png|jpg|jpeg\";
$statsd_key = "first_byte";</p>

<p>exec( $cmd, $log_lines );</p>

<p>foreach ( $log_lines as $line ) {</p>

<p>  $line_items = explode( ' ', $line );</p>

<p>  $firstbyte = $line_items[ count($line_items) - 1 ];</p>

<p>  $firstbyte_ms = ceil( ( $firstybyte / 1000 ) );</p>

<p>  StatsD::timing( $statsd_key, $firstybyte_ms );</p>

<p>} // foreach log lines</p>

<p>```</p>

<p>And voilà, you now have some very revealing graphs that will tell you exactly your app is performing, completely separate of how the hellion ISPs have decided to perform that moment. My favorite thing about these graphs is that they are an unopinionated view of how the last changes you've made have affected your app.</p>
]]></content>
  </entry>
  
</feed>
